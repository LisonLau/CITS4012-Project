{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden, aspect):\n",
    "        word_embedding = self.embedding(input).view(1, 1, -1)\n",
    "        aspect_embedding = self.embedding(aspect).view(1, 1, -1)\n",
    "        word_embedding = torch.cat((word_embedding, aspect_embedding), 0)\n",
    "        output, hidden = self.gru(word_embedding, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "# Decoder\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding, dropout_p=0.1):\n",
    "        super(GRUDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding = embedding\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
    "    \n",
    "    def cal_attention(self, hidden, encoder_hiddens):\n",
    "        attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)), dim=-1)\n",
    "        attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
    "        concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
    "        return concat_output\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_hiddens):\n",
    "        word_embedding = self.embedding(input).view(1, 1, -1)\n",
    "        word_embedding = self.dropout(word_embedding)\n",
    "        _, hidden = self.gru(word_embedding, hidden)\n",
    "        concat_output = self.cal_attention(hidden, encoder_hiddens)\n",
    "        output = F.log_softmax(self.out(concat_output), dim=1)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 4012\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "num_epochs = 200\n",
    "display_interval = 20\n",
    "learning_rate = 0.01\n",
    "hidden_size = 50\n",
    "embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "encoder = GRUEncoder(hidden_size, embedding)\n",
    "decoder = GRUDecoder(hidden_size, vocab_size, embedding, dropout_p=0.1) # vocab_size?\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "plot_losses = []\n",
    "plot_avg_losses = []\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    random_idx = random.choice(range(len(train_data)))\n",
    "    x_index = [[idx] for idx in train_x_idx[random_idx]]\n",
    "    y_index = [[idx] for idx in target_y_idx[random_idx]]\n",
    "    a_index = train_a_idx[random_idx]\n",
    "    \n",
    "    x_tensor = torch.LongTensor(x_index)\n",
    "    y_tensor = torch.LongTensor(y_index)\n",
    "    a_tensor = torch.LongTensor([a_index])\n",
    "    x_length = x_tensor.size(0)\n",
    "    y_length = y_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Feed the x_tensor (sentence) into the encoder\n",
    "    encoder_hiddens = torch.zeros(MAX_LENGTH, encoder.hidden_size) # For attention mechanism\n",
    "    encoder_hidden = encoder.init_hidden() # Hidden state for encoder\n",
    "    for i in range(x_length):\n",
    "        encoder_output, encoder_hidden = encoder(x_tensor[i], encoder_hidden, a_tensor)\n",
    "        encoder_hiddens[i] = encoder_hidden[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[word_to_idx[\"<BOS>\"]]]) \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Feed the y_tensor (polarity) into the decoder with teacher forcing\n",
    "    for i in range(y_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n",
    "        loss += criterion(decoder_output, y_tensor[i])\n",
    "        decoder_input = y_tensor[i]\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    loss = loss.item() / y_length\n",
    "    total_loss += loss\n",
    "    plot_losses.append(loss)\n",
    "    \n",
    "    if (epoch+1) % display_interval == 0:\n",
    "        avg_loss = total_loss / display_interval\n",
    "        plot_avg_losses.append(avg_loss)\n",
    "        total_loss = 0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU evaluate\n",
    "def GRUevaluate(encoder, decoder, sentence, aspect, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input = preprocess_data([sentence])[0]\n",
    "        input_idx = [word_to_idx[word] for word in input]\n",
    "        input_tensor = torch.LongTensor([[ind] for ind in input_idx])\n",
    "        \n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "        \n",
    "        asp_idx = word_to_idx[aspect]\n",
    "        asp_tensor = torch.LongTensor([[asp_idx]])\n",
    "\n",
    "        encoder_hiddens = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden, asp_tensor)\n",
    "            encoder_hiddens[ei] += encoder_hidden[0, 0]\n",
    "\n",
    "        decoder_input = torch.LongTensor([[word_to_idx[\"<BOS>\"]]]) \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == word_to_idx[\"<EOS>\"]:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(word_list[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the GRU model using the test data\n",
    "for i in range(len(test_x[:10])):\n",
    "    polarity = GRUevaluate(encoder, decoder, test_x[i], test_a[i])[0]\n",
    "    print(f\"Predicted polarity: {polarity}, Actual polarity: {test_y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure accuracy of GRU model on test set\n",
    "correct = 0\n",
    "for i in range(len(test_x)):\n",
    "    polarity = GRUevaluate(encoder, decoder, test_x[i], test_a[i])[0]\n",
    "    if polarity == test_y[i]:\n",
    "        correct += 1\n",
    "accuracy = correct / len(test_x_token)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden, aspect):\n",
    "        word_embedding = self.embedding(input).view(1, 1, -1)\n",
    "        aspect_embedding = self.embedding(aspect).view(1, 1, -1)\n",
    "        word_embedding = torch.cat((aspect_embedding, word_embedding), 0)\n",
    "        output, hidden = self.gru(word_embedding, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, attention='dot_product'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.attention_type = attention\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.linear = nn.Linear(self.hidden_size*2, self.output_size)\n",
    "    \n",
    "    def cal_attention(self, hidden, encoder_hiddens):\n",
    "        if self.attention_type == 'dot_product':            # Dot product attention\n",
    "            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)), dim=-1)\n",
    "        elif self.attention_type == 'scaled_dot_product':   # Scaled dot product attention\n",
    "            scale = 1.0 / np.sqrt(self.hidden_size)\n",
    "            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)) * scale, dim=-1)\n",
    "        elif self.attention_type == 'cosine_similarity':\n",
    "            query = hidden / torch.norm(hidden, dim=-1)\n",
    "            keys = encoder_hiddens / torch.norm(encoder_hiddens.T, dim=-1)\n",
    "            norm_product = torch.bmm(query, keys.T.unsqueeze(0))\n",
    "            attn_weights = F.softmax(norm_product, dim=-1)\n",
    "\n",
    "        attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
    "        concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
    "        return concat_output\n",
    "    \n",
    "    def forward(self, hidden, encoder_hiddens):\n",
    "        concat_output = self.cal_attention(hidden, encoder_hiddens)\n",
    "        output = F.log_softmax(self.linear(concat_output), dim=1)\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "# seed = 4012\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "\n",
    "num_epochs = 10000\n",
    "display_interval = 500\n",
    "learning_rate = 0.01\n",
    "hidden_size = 50\n",
    "attention_type = 'dot_product' # 'dot_product', 'scaled_dot_product', 'cosine_similarity'\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(glove_weights)\n",
    "embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "encoder = Encoder(hidden_size, embedding)\n",
    "decoder = Decoder(hidden_size, 3, attention=attention_type)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "plot_losses = []\n",
    "plot_avg_losses = []\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    random_idx = random.choice(range(len(train_data)))\n",
    "    x_index = [[idx] for idx in train_x_idx[random_idx]]\n",
    "    y_index = train_y_idx[random_idx]\n",
    "    a_index = train_a_idx[random_idx]\n",
    "    \n",
    "    x_tensor = torch.LongTensor(x_index)\n",
    "    y_tensor = torch.LongTensor([y_index])\n",
    "    a_tensor = torch.LongTensor([a_index])\n",
    "    x_length = x_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Feed the x_tensor (sentence) into the encoder\n",
    "    encoder_hiddens = torch.zeros(MAX_LENGTH, encoder.hidden_size) # For attention mechanism\n",
    "    encoder_hidden = encoder.init_hidden() # Hidden state for encoder\n",
    "    for i in range(x_length):\n",
    "        encoder_output, encoder_hidden = encoder(x_tensor[i], encoder_hidden, a_tensor)\n",
    "        encoder_hiddens[i] = encoder_hidden[0, 0]\n",
    "\n",
    "    y_output = decoder(encoder_hidden, encoder_hiddens)\n",
    "    loss += criterion(y_output, y_tensor)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    loss = loss.item()\n",
    "    total_loss += loss\n",
    "    plot_losses.append(loss)\n",
    "    \n",
    "    if (epoch+1) % display_interval == 0:\n",
    "        avg_loss = total_loss / display_interval\n",
    "        plot_avg_losses.append(avg_loss)\n",
    "        total_loss = 0\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(encoder, 'Model/encoder1.pt')\n",
    "# torch.save(decoder, 'Model1/decoder1.pt')\n",
    "\n",
    "# Plot loss over number of epochs\n",
    "plt.plot(range(1, num_epochs+1), plot_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over number of epochs')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, num_epochs+1, display_interval), plot_avg_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over number of epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU evaluate\n",
    "def GRUevaluate(encoder, decoder, sentence, aspect, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input = preprocess_data([sentence])[0]\n",
    "        input_idx = [word_to_idx[word] for word in input]\n",
    "        input_tensor = torch.LongTensor([[ind] for ind in input_idx])\n",
    "        \n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "        \n",
    "        asp_idx = word_to_idx[aspect]\n",
    "        asp_tensor = torch.LongTensor([[asp_idx]])\n",
    "\n",
    "        encoder_hiddens = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden, asp_tensor)\n",
    "            encoder_hiddens[ei] += encoder_hidden[0, 0]\n",
    "        \n",
    "        y_pred = decoder(encoder_hidden, encoder_hiddens)\n",
    "        topv, topi = y_pred.data.topk(1)\n",
    "        return idx_to_polarity[topi.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure accuracy of LSTM model on test set\n",
    "correct = 0\n",
    "for i in range(len(test_x)):\n",
    "    polarity = GRUevaluate(encoder, decoder, test_x[i], test_a[i])\n",
    "    if polarity == test_y[i]:\n",
    "        correct += 1\n",
    "accuracy = correct / len(test_x_token)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
